{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook illustrates applications of monkey-patching in Python. It also demonstrates some cool applications of the [inspect](https://docs.python.org/3/library/inspect.html) module.\n",
    "\n",
    "**Author:** Tom McTavish\n",
    "\n",
    "**Date:** November 18, 2020\n",
    "\n",
    "# Introduction\n",
    "\n",
    "## Definition\n",
    "\n",
    "Monkey-patching is the process of inserting code during run-time, modifying the running instance, without modifying the original code.\n",
    "\n",
    "## WARNING:\n",
    "\n",
    "Monkey-patching should be avoided in production. This is because the running instance of software should be explicit -- reflected by what is on disk. Monkey patching also makes assumptions of what is on disk and the running state. If that software changes, the patch may not work as intended.\n",
    "\n",
    "## Applications during development\n",
    "\n",
    "Monkey-patching with respect to Data Science workflows is useful when we want to:\n",
    "\n",
    "  * **Dive deeper with running objects, especially library objects.** We may want to understand a particular object's method in more detail. While we can see the code using the `inspect` module, we may want to log activity to see internal workings.\n",
    "  \n",
    "  * **Accelerate iterative development.** During the enhancement of an object's method, the typical flow is to make a code change, reinstantiate the object, then call the object's method, and repeat as necessary. For many objects, this is not problematic, but say you have a model that takes time to train. It can be quite tedious to retrain with each instantiation. As well, if the object is in Python module that we are updating, we may need to restart the Python kernel to reimport the module. This may also mean reloading large data sources, etc. \n",
    "\n",
    "We will look at these two scenarios, but first, let's look at a basic template.\n",
    "\n",
    "# Monkey Patch Instance Method Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patch_func\n",
      "class_func\n"
     ]
    }
   ],
   "source": [
    "import types\n",
    "\n",
    "class MyClass:\n",
    "    def class_func(self):\n",
    "        print(\"class_func\")\n",
    "        \n",
    "def patch_func(self):\n",
    "    print(\"patch_func\")\n",
    "\n",
    "# Make 2 instances of MyClass\n",
    "obj = MyClass()\n",
    "obj2 = MyClass()\n",
    "\n",
    "# Modify `class_func()` in the first instance\n",
    "obj.class_func = types.MethodType(patch_func, obj)\n",
    "\n",
    "# Call `class_func()` in both objects\n",
    "obj.class_func()  # Calls our patch\n",
    "obj2.class_func()  # Calls the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The template above is the basic technique. Below, we show some applications.\n",
    "\n",
    "# Examples\n",
    "\n",
    "## Monkey Patching during iterative model development\n",
    "\n",
    "In the following example, we show how we can apply monkey patching to an already-trained model. This allows us to fix bugs, make modifications, or add attributes to an existing model without having to retrain it to utilize the code changes. Ultimately, when we are finished, we should retrain the model completely. But this demo is to show how we can do development on a trained model.\n",
    "\n",
    "This example uses DHI's Match Team [dsmatch](https://bitbucket.org/dhigroupinc/dhi-match-datascience/src/master/) library and the [efc-ensemble-3dim-20201103](https://bitbucket.org/dhigroupinc/dhi-match-models/src/master/efc-ensemble-3dim-20201103/) model. The cell below ensures specific versions of the packages so the model will run correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install --upgrade tqdm\n",
    "\n",
    "!pip install -e git+ssh://git@bitbucket.org/dhigroupinc/dhi-match-datascience.git@4164b8c#egg=dsmatch\n",
    "\n",
    "!pip install beautifulsoup4==4.8.2\n",
    "!pip install boto==2.49.0\n",
    "!pip install boto3==1.16.9\n",
    "!pip install botocore==1.19.9\n",
    "!pip install contractions==0.0.25\n",
    "!pip install ipywidgets==7.5.1\n",
    "!pip install joblib==0.17.0\n",
    "!pip install json5==0.9.1\n",
    "!pip install jsonpath-ng==1.5.2\n",
    "!pip install jsonschema==3.2.0\n",
    "!pip install line-profiler==3.1.0\n",
    "!pip install nltk==3.4.5\n",
    "!pip install numpy==1.18.1\n",
    "!pip install pandas==1.1.4\n",
    "!pip install s3fs==0.4.2\n",
    "!pip install s3transfer==0.3.3\n",
    "!pip install scikit-image==0.16.2\n",
    "!pip install scikit-learn==0.22.1\n",
    "!pip install scipy==1.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and read data to send to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job-title</th>\n",
       "      <th>job-description</th>\n",
       "      <th>current_job_title</th>\n",
       "      <th>resume</th>\n",
       "      <th>match_score</th>\n",
       "      <th>set</th>\n",
       "      <th>Source</th>\n",
       "      <th>Language</th>\n",
       "      <th>jdtext</th>\n",
       "      <th>resume_clean</th>\n",
       "      <th>job_description_clean</th>\n",
       "      <th>job_title_clean</th>\n",
       "      <th>job-data-bg_skills</th>\n",
       "      <th>resume-data-bg_skills</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>row_0000</th>\n",
       "      <td>Aluminium Casting Specialist, Can Body Stock</td>\n",
       "      <td>Redstone Commodity Search are working with an ...</td>\n",
       "      <td>Aluminum designer and planning engineer</td>\n",
       "      <td>E D U C A T I O N\\r\\n\\r\\n Bachelor Degree in ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>e c n bachelor degre civil engin buÌˆlent ecevi...</td>\n",
       "      <td>redston commod search work intern metal produc...</td>\n",
       "      <td>aluminium cast specialist bodi stock.</td>\n",
       "      <td>[3D Printing / Additive Manufacturing (AM), On...</td>\n",
       "      <td>[AutoCAD, Civil Engineering, ISO 9001 Standard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0001</th>\n",
       "      <td>Remittance Officer [Banking] (ID: 483271)</td>\n",
       "      <td>Your key roles &amp; responsibilities include:  Ha...</td>\n",
       "      <td>Manger Operation</td>\n",
       "      <td>CAREER OBJECTIVE \\r\\n\\r\\n Seeking an opportun...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>career object seek opportun career advanc chal...</td>\n",
       "      <td>key roles_and_respons includ handl daytoday tr...</td>\n",
       "      <td>remitt offic bank id 483271.</td>\n",
       "      <td>[Communication Skills, Preparing Reports]</td>\n",
       "      <td>[Chinese, External Auditing, Global Positionin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0002</th>\n",
       "      <td>Investment Banking Associate, Singapore based</td>\n",
       "      <td>Responsibilities would include:  Supporting ...</td>\n",
       "      <td>Unit Manager</td>\n",
       "      <td>STEVEN CHOOI HOONG KIT\\r\\n\\r\\n6, Tingkat Falim...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>steven chooi hoong kit 6 tingkat falim 5 taman...</td>\n",
       "      <td>respons would includ support origin structur e...</td>\n",
       "      <td>invest bank associ singapor base.</td>\n",
       "      <td>[Business Development, Customer Contact, Detai...</td>\n",
       "      <td>[Appointment Setting, Business Administration,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0003</th>\n",
       "      <td>Research Analyst - Systematic Macro</td>\n",
       "      <td>Responsibilities  Managing all aspects of the ...</td>\n",
       "      <td>Quantitative Analyst</td>\n",
       "      <td>2.4 Askew Building, 50 Bartholomew Close, Lon...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2_dot_4 askew build 50 bartholomew close londo...</td>\n",
       "      <td>respons manag aspect research process includ m...</td>\n",
       "      <td>research analyst systemat macro.</td>\n",
       "      <td>[Data Collection, Detail-Oriented, Fixed Incom...</td>\n",
       "      <td>[Active Alpha Generation, Asset Management Ind...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0004</th>\n",
       "      <td>AVP, PRODUCT MANAGER</td>\n",
       "      <td>Product Development / Project Management Inno...</td>\n",
       "      <td>Senior product manager</td>\n",
       "      <td>Kuanzhao Huang \\r\\n\\r\\nâš« 61210214 \\r\\nâš« foonwo...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>train</td>\n",
       "      <td>NaN</td>\n",
       "      <td>en</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kuanzhao huang âš« 61210214 âš« foonwong511_at_gma...</td>\n",
       "      <td>product development_slash_project manag innov ...</td>\n",
       "      <td>avp product manag.</td>\n",
       "      <td>[Communication Skills, Planning, Problem Solvi...</td>\n",
       "      <td>[Business Planning, Business Process, Business...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              job-title  \\\n",
       "row_id                                                    \n",
       "row_0000   Aluminium Casting Specialist, Can Body Stock   \n",
       "row_0001      Remittance Officer [Banking] (ID: 483271)   \n",
       "row_0002  Investment Banking Associate, Singapore based   \n",
       "row_0003            Research Analyst - Systematic Macro   \n",
       "row_0004                           AVP, PRODUCT MANAGER   \n",
       "\n",
       "                                            job-description  \\\n",
       "row_id                                                        \n",
       "row_0000  Redstone Commodity Search are working with an ...   \n",
       "row_0001  Your key roles & responsibilities include:  Ha...   \n",
       "row_0002  Â  Responsibilities would include:  Supporting ...   \n",
       "row_0003  Responsibilities  Managing all aspects of the ...   \n",
       "row_0004   Product Development / Project Management Inno...   \n",
       "\n",
       "                                current_job_title  \\\n",
       "row_id                                              \n",
       "row_0000  Aluminum designer and planning engineer   \n",
       "row_0001                         Manger Operation   \n",
       "row_0002                             Unit Manager   \n",
       "row_0003                     Quantitative Analyst   \n",
       "row_0004                   Senior product manager   \n",
       "\n",
       "                                                     resume  match_score  \\\n",
       "row_id                                                                     \n",
       "row_0000   E D U C A T I O N\\r\\n\\r\\n Bachelor Degree in ...          3.0   \n",
       "row_0001   CAREER OBJECTIVE \\r\\n\\r\\n Seeking an opportun...          2.0   \n",
       "row_0002  STEVEN CHOOI HOONG KIT\\r\\n\\r\\n6, Tingkat Falim...          3.0   \n",
       "row_0003   2.4 Askew Building, 50 Bartholomew Close, Lon...          4.0   \n",
       "row_0004  Kuanzhao Huang \\r\\n\\r\\nâš« 61210214 \\r\\nâš« foonwo...          4.0   \n",
       "\n",
       "            set Source Language jdtext  \\\n",
       "row_id                                   \n",
       "row_0000  train    NaN       en    NaN   \n",
       "row_0001  train    NaN       en    NaN   \n",
       "row_0002   test    NaN       en    NaN   \n",
       "row_0003   test    NaN       en    NaN   \n",
       "row_0004  train    NaN       en    NaN   \n",
       "\n",
       "                                               resume_clean  \\\n",
       "row_id                                                        \n",
       "row_0000  e c n bachelor degre civil engin buÌˆlent ecevi...   \n",
       "row_0001  career object seek opportun career advanc chal...   \n",
       "row_0002  steven chooi hoong kit 6 tingkat falim 5 taman...   \n",
       "row_0003  2_dot_4 askew build 50 bartholomew close londo...   \n",
       "row_0004  kuanzhao huang âš« 61210214 âš« foonwong511_at_gma...   \n",
       "\n",
       "                                      job_description_clean  \\\n",
       "row_id                                                        \n",
       "row_0000  redston commod search work intern metal produc...   \n",
       "row_0001  key roles_and_respons includ handl daytoday tr...   \n",
       "row_0002  respons would includ support origin structur e...   \n",
       "row_0003  respons manag aspect research process includ m...   \n",
       "row_0004  product development_slash_project manag innov ...   \n",
       "\n",
       "                                 job_title_clean  \\\n",
       "row_id                                             \n",
       "row_0000  aluminium cast specialist bodi stock.    \n",
       "row_0001           remitt offic bank id 483271.    \n",
       "row_0002      invest bank associ singapor base.    \n",
       "row_0003       research analyst systemat macro.    \n",
       "row_0004                     avp product manag.    \n",
       "\n",
       "                                         job-data-bg_skills  \\\n",
       "row_id                                                        \n",
       "row_0000  [3D Printing / Additive Manufacturing (AM), On...   \n",
       "row_0001          [Communication Skills, Preparing Reports]   \n",
       "row_0002  [Business Development, Customer Contact, Detai...   \n",
       "row_0003  [Data Collection, Detail-Oriented, Fixed Incom...   \n",
       "row_0004  [Communication Skills, Planning, Problem Solvi...   \n",
       "\n",
       "                                      resume-data-bg_skills  \n",
       "row_id                                                       \n",
       "row_0000  [AutoCAD, Civil Engineering, ISO 9001 Standard...  \n",
       "row_0001  [Chinese, External Auditing, Global Positionin...  \n",
       "row_0002  [Appointment Setting, Business Administration,...  \n",
       "row_0003  [Active Alpha Generation, Asset Management Ind...  \n",
       "row_0004  [Business Planning, Business Process, Business...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, './src/dsmatch/')  # prepend sys.path with this dsmatch so it uses this one, not a different one.\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from dhi.dsmatch.sklearnmodeling.models.bgskillsoptimalassignment import BGSkills\n",
    "from dhi.dsmatch.sklearnmodeling.models.ndimcostfidf import NDimCosTfidf\n",
    "from dhi.dsmatch.sklearnmodeling.models.compositetransformer import CompositeTransformer, ModelPackage\n",
    "\n",
    "from dhi.dsmatch.util.io import read_csv, load_joblib\n",
    "from dhi.dsmatch import local_bucket, s3_ds_bucket\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "\n",
    "# Read in the data we'll use.\n",
    "path = os.path.join('data', 'efc', 'unsupervised')\n",
    "filename = 'validation-skills-20201030.csv'\n",
    "df = read_csv(path, filename)\n",
    "\n",
    "# The lists in the dataframe are intepreted as strings and not lists, we need to make them lists of strings.\n",
    "idxs = df[df['job-data-bg_skills'].isnull()].index\n",
    "df.loc[idxs, 'job-data-bg_skills'] = \"[]\"\n",
    "df.loc[:, 'job-data-bg_skills'] = df.loc[:, 'job-data-bg_skills'].apply(eval)\n",
    "idxs = df[df['resume-data-bg_skills'].isnull()].index\n",
    "df.loc[idxs, 'resume-data-bg_skills'] = \"[]\"\n",
    "df.loc[:, 'resume-data-bg_skills'] = df.loc[:, 'resume-data-bg_skills'].apply(eval)\n",
    "df.set_index('row_id', inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_joblib(key=os.path.join('models', 'efc', 'unsupervised', 'efc-ensemble-3dim-20201103.joblib'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Send some data through the model.\n",
    "\n",
    "Below, we select the subset of columns from the dataframe that the model is expecting and call its `transform()` method on the first row -- much like if we were asking for a prediction during runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_cossim</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_score</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_resume_n_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_job-description_n_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_min_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_confidence</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_cossim</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_score</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_resume_n_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_job-title_n_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_min_nonzero</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_confidence</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|n_skills_jd</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|n_skills_res</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|n_skills</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|top-skills</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|score</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|confidence</th>\n",
       "      <th>confidence</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_confimprt</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_confimprt</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|confimprt</th>\n",
       "      <th>confidence_total</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_relative_weight</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_relative_weight</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|relative_weight</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-description_contribution</th>\n",
       "      <th>NDimCosTfidf|cossim-resume_job-title_contribution</th>\n",
       "      <th>efc_bgskills_pairwise_optimal_assignment|contribution</th>\n",
       "      <th>score</th>\n",
       "      <th>quantile</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055976</td>\n",
       "      <td>0.0455203</td>\n",
       "      <td>120</td>\n",
       "      <td>78</td>\n",
       "      <td>78</td>\n",
       "      <td>0.486583</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.451188</td>\n",
       "      <td>15</td>\n",
       "      <td>42</td>\n",
       "      <td>15</td>\n",
       "      <td>[{'job_description': '3d printing / additive m...</td>\n",
       "      <td>0.468546</td>\n",
       "      <td>0.464739</td>\n",
       "      <td>0.467503</td>\n",
       "      <td>0.540324</td>\n",
       "      <td>0.367908</td>\n",
       "      <td>0.215578</td>\n",
       "      <td>1.12381</td>\n",
       "      <td>0.480796</td>\n",
       "      <td>0.327376</td>\n",
       "      <td>0.191828</td>\n",
       "      <td>0.021886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0898802</td>\n",
       "      <td>0.111766</td>\n",
       "      <td>0.09439</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  NDimCosTfidf|cossim-resume_job-description_cossim  \\\n",
       "0                                          0.055976   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_score  \\\n",
       "0                                        0.0455203   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_resume_n_nonzero  \\\n",
       "0                                                120            \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_job-description_n_nonzero  \\\n",
       "0                                                 78                     \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_min_nonzero  \\\n",
       "0                                                 78       \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_confidence  \\\n",
       "0                                           0.486583      \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_cossim  \\\n",
       "0                                           0   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_score  \\\n",
       "0                                          0   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_resume_n_nonzero  \\\n",
       "0                                                120      \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_job-title_n_nonzero  \\\n",
       "0                                                  3         \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_min_nonzero  \\\n",
       "0                                                3   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_confidence  \\\n",
       "0                                        0.451188   \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|n_skills_jd  \\\n",
       "0                                                 15     \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|n_skills_res  \\\n",
       "0                                                 42      \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|n_skills  \\\n",
       "0                                                15   \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|top-skills  \\\n",
       "0  [{'job_description': '3d printing / additive m...    \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|score  \\\n",
       "0                                       0.468546   \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|confidence  confidence  \\\n",
       "0                                           0.464739     0.467503   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_confimprt  \\\n",
       "0                                           0.540324     \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_confimprt  \\\n",
       "0                                       0.367908   \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|confimprt  confidence_total  \\\n",
       "0                                           0.215578           1.12381   \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_relative_weight  \\\n",
       "0                                           0.480796           \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_relative_weight  \\\n",
       "0                                           0.327376     \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|relative_weight  \\\n",
       "0                                           0.191828         \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-description_contribution  \\\n",
       "0                                           0.021886        \n",
       "\n",
       "  NDimCosTfidf|cossim-resume_job-title_contribution  \\\n",
       "0                                                 0   \n",
       "\n",
       "  efc_bgskills_pairwise_optimal_assignment|contribution     score  quantile  \\\n",
       "0                                          0.0898802     0.111766   0.09439   \n",
       "\n",
       "   pred  \n",
       "0     2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['resume', 'job-description', 'job-title', 'job-data-bg_skills', 'resume-data-bg_skills']\n",
    "df_ = df.loc[:, cols]\n",
    "resp = model.transform(df_.iloc[:1])\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### Create a `detailed_predict()` function.\n",
    "\n",
    "Let's create a `detailed_predict()` object method that converts this table into a nicely formatted JSON/dict structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NDimCosTfidf|cossim-resume_job-description_cossim': {0: 0.05597602135763841},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_score': {0: 0.04552030290124594},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_resume_n_nonzero': {0: 120.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_job-description_n_nonzero': {0: 78.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_min_nonzero': {0: 78.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_confidence': {0: 0.486582880967408},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_cossim': {0: 0.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_score': {0: 0.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_resume_n_nonzero': {0: 120.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_job-title_n_nonzero': {0: 3.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_min_nonzero': {0: 3.0},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_confidence': {0: 0.4511883639059736},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|n_skills_jd': {0: 15},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|n_skills_res': {0: 42},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|n_skills': {0: 15},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|top-skills': {0: [{'job_description': '3d printing / additive manufacturing (am)',\n",
       "    'resume': 'autocad',\n",
       "    'match': 0.6395998358499044},\n",
       "   {'job_description': 'onboarding',\n",
       "    'resume': 'human resources',\n",
       "    'match': 0.5720728015100564},\n",
       "   {'job_description': 'technical assistance',\n",
       "    'resume': 'project management',\n",
       "    'match': 0.5225403892055068},\n",
       "   {'job_description': 'process engineering',\n",
       "    'resume': 'engineering',\n",
       "    'match': 0.514655725038509}]},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|score': {0: 0.46854626675244815},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|confidence': {0: 0.4647385714810097},\n",
       " 'confidence': {0: 0.4675032721181305},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_confimprt': {0: 0.540323725724167},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_confimprt': {0: 0.36790828907730805},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|confimprt': {0: 0.21557796071978455},\n",
       " 'confidence_total': {0: 1.1238099755212596},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_relative_weight': {0: 0.4807963423474216},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_relative_weight': {0: 0.32737588835395437},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|relative_weight': {0: 0.19182776929862408},\n",
       " 'NDimCosTfidf|cossim-resume_job-description_contribution': {0: 0.02188599513746577},\n",
       " 'NDimCosTfidf|cossim-resume_job-title_contribution': {0: 0.0},\n",
       " 'efc_bgskills_pairwise_optimal_assignment|contribution': {0: 0.0898801851643202},\n",
       " 'score': {0: 0.11176618030178596},\n",
       " 'quantile': {0: 0.09438960466986794},\n",
       " 'pred': {0: 2}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def detailed_predict(self, X, **kwargs):\n",
    "    \"\"\"Call `transform()`, but yield results in a dict format.\n",
    "\n",
    "    Args:\n",
    "        X (DataFrame): Input data to transform.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Overall results and each submodel results.\n",
    "    \"\"\"\n",
    "    X = self.transform(X, **kwargs)  # Get our transformed dataframe\n",
    "    return X.to_dict()  # Output as a dict\n",
    "\n",
    "model.detailed_predict = types.MethodType(detailed_predict, model)  # Apply the patch\n",
    "resp = model.detailed_predict(df_.iloc[:1])  # Call it\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interesting first stab, but not in the correct format...\n",
    "\n",
    "Of course, the production team wanted the outputs in a different, more generalizable and readable format. Below is the final format of this method, which you can imagine required several iterations to tease column names apart, ignore some fields, and apply various formatting to arrive at the final desired output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'overall_class': 2,\n",
       " 'overall_name': 'efc_ensemble_3Dim',\n",
       " 'overall_version': '1.0.0',\n",
       " 'overall_score': 0.09438960466986794,\n",
       " 'ensemble_name': 'efc_ensemble_3Dim',\n",
       " 'ensemble_score': 0.09438960466986794,\n",
       " 'ensemble_class': 2,\n",
       " 'ensemble_version': '1.0.0',\n",
       " 'ensemble_confidence': 0.4675032721181305,\n",
       " 'ensemble_submodels': [{'domain': 'text',\n",
       "   'name': 'cossim-resume_job-description',\n",
       "   'version': '1.0.0',\n",
       "   'score': 0.04552030290124594,\n",
       "   'confidence': 0.486582880967408,\n",
       "   'importance': 0.6,\n",
       "   'applied_weighting': 0.4807963423474216,\n",
       "   'explain': {'cossim': 0.05597602135763841,\n",
       "    'resume_n_nonzero': 120.0,\n",
       "    'job-description_n_nonzero': 78.0,\n",
       "    'min_nonzero': 78.0}},\n",
       "  {'domain': 'text',\n",
       "   'name': 'cossim-resume_job-title',\n",
       "   'version': '1.0.0',\n",
       "   'score': 0.0,\n",
       "   'confidence': 0.4511883639059736,\n",
       "   'importance': 0.3,\n",
       "   'applied_weighting': 0.32737588835395437,\n",
       "   'explain': {'cossim': 0.0,\n",
       "    'resume_n_nonzero': 120.0,\n",
       "    'job-title_n_nonzero': 3.0,\n",
       "    'min_nonzero': 3.0}},\n",
       "  {'domain': 'skills',\n",
       "   'name': 'efc_bgskills_pairwise_optimal_assignment',\n",
       "   'version': '1.0.0',\n",
       "   'score': 0.46854626675244815,\n",
       "   'confidence': 0.4647385714810097,\n",
       "   'importance': 0.1,\n",
       "   'applied_weighting': 0.19182776929862408,\n",
       "   'explain': {'n_skills_jd': 15,\n",
       "    'n_skills_res': 42,\n",
       "    'n_skills': 15,\n",
       "    'top-skills': [{'job_description': '3d printing / additive manufacturing (am)',\n",
       "      'resume': 'autocad',\n",
       "      'match': 0.6395998358499044},\n",
       "     {'job_description': 'onboarding',\n",
       "      'resume': 'human resources',\n",
       "      'match': 0.5720728015100564},\n",
       "     {'job_description': 'technical assistance',\n",
       "      'resume': 'project management',\n",
       "      'match': 0.5225403892055068},\n",
       "     {'job_description': 'process engineering',\n",
       "      'resume': 'engineering',\n",
       "      'match': 0.514655725038509}]}}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detailed_predict(self, X, **kwargs):\n",
    "    \"\"\"Call `transform()`, but yield results in a dict format.\n",
    "\n",
    "    Args:\n",
    "        X (DataFrame): Input data to transform.\n",
    "\n",
    "    Returns:\n",
    "        Dict: Overall results and each submodel results.\n",
    "    \"\"\"\n",
    "    X = self.transform(X, **kwargs)\n",
    "    score_cols = [c for c in X.columns if c.endswith('|score') or c.endswith('_score')]\n",
    "    model_headers = [c[:-5] for c in score_cols]\n",
    "    submodels = []\n",
    "    for model_header in model_headers:\n",
    "        if model_header[-1] == '|':\n",
    "            model_name = model_header[:-1]\n",
    "        else:\n",
    "            splitted = model_header.split('|')\n",
    "            model_name = splitted[-1][:-1]\n",
    "        cols = [c for c in X.columns if c.startswith(model_header)]\n",
    "        cols = [c for c in cols if not (c.endswith('score') \n",
    "                                        or c.endswith('confidence') \n",
    "                                        or c.endswith('relative_weight')\n",
    "                                        or c.endswith('confimprt')\n",
    "                                        or c.endswith('contribution'))]\n",
    "        new_cols = [c[len(model_header):] for c in cols]\n",
    "        explain = np.squeeze(\n",
    "            X[cols].rename(columns=dict(zip(cols, new_cols)))\\\n",
    "            .to_dict(orient='records')).tolist()\n",
    "        submodel = self.submodels_dict[model_name]\n",
    "        submodels.append(dict(\n",
    "            domain = submodel.domain,\n",
    "            name = submodel.model.name,\n",
    "            version = submodel.model.version,\n",
    "            score = np.squeeze(X[model_header + 'score'].values).tolist(),\n",
    "            confidence = np.squeeze(X[model_header + 'confidence'].values).tolist(),\n",
    "            importance = submodel.importance,\n",
    "            applied_weighting = np.squeeze(X[model_header + 'relative_weight'].values).tolist(),\n",
    "            explain = explain\n",
    "        ))\n",
    "\n",
    "    # TODO: \"overall_\" fields below are temporary and should be removed when we have a true \"overall\" model\n",
    "    # and where this ensemble model is a subset of the overall results.\n",
    "    return dict(overall_class=np.squeeze(X['pred']).tolist(),\n",
    "                overall_name=self.name,\n",
    "                overall_version=self.version,\n",
    "                overall_score=np.squeeze(X['quantile']).tolist(),\n",
    "                ensemble_name=self.name,\n",
    "                ensemble_score=np.squeeze(X['quantile']).tolist(),\n",
    "                ensemble_class=np.squeeze(X['pred']).tolist(),\n",
    "                ensemble_version=self.version,\n",
    "                ensemble_confidence=np.squeeze(X['confidence']).tolist(),\n",
    "                ensemble_submodels=submodels\n",
    "            )\n",
    "\n",
    "model.detailed_predict = types.MethodType(detailed_predict, model)  # Apply/update our patch\n",
    "resp = model.detailed_predict(df_.iloc[:1])  # Call the method\n",
    "resp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes the illustration of adding functionality to an existing model where we have direct control of the source and can update that library code and retrain the model.\n",
    "\n",
    "## Interrogating external code: An Sklearn example\n",
    "\n",
    "In the next example, we will show how we can use the [inspect](https://docs.python.org/3/library/inspect.html) module and monkey patching to interrogate external code, in this case, an sklearn [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n",
    "\n",
    "Besides looking at the [source code](https://github.com/scikit-learn/scikit-learn/blob/0fb307bf3/sklearn/tree/_classes.py) to understand it, monkey patching permits us to insert print or log statements in the code, or to make modifications to see their impact.\n",
    "\n",
    "In the following example, we are interested in seeing more how the DecisionTreeClassier's `fit()` function works. We will start by loading the [Iris flower data set](https://en.wikipedia.org/wiki/Iris_flower_data_set), fitting it, and visualizing the tree that is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x1440 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "\n",
    "# Load data\n",
    "iris = load_iris()\n",
    "n_classes = len(iris.target_names)\n",
    "\n",
    "plt.figure(figsize=(10, 12), dpi=120)\n",
    "clf = DecisionTreeClassifier(random_state=0).fit(iris.data, iris.target)\n",
    "plot_tree(clf, feature_names_out=iris.feature_names_out, class_names=iris.target_names, filled=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `inspect` to see what that `fit()` function is doing.\n",
    "\n",
    "To see the source code of the fit function, we can call `inspect.getsource()` with the class and its member function to see its output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
      "            X_idx_sorted=None):\n",
      "        \"\"\"Build a decision tree classifier from the training set (X, y).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (class labels) as integers or strings.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node. Splits are also\n",
      "            ignored if they would result in any single class carrying a\n",
      "            negative weight in either child node.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        X_idx_sorted : array-like of shape (n_samples, n_features), \\\n",
      "                default=None\n",
      "            The indexes of the sorted training input samples. If many tree\n",
      "            are grown on the same dataset, this allows the ordering to be\n",
      "            cached between trees. If None, the data will be sorted here.\n",
      "            Don't use this parameter unless you know what to do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : DecisionTreeClassifier\n",
      "            Fitted estimator.\n",
      "        \"\"\"\n",
      "\n",
      "        super().fit(\n",
      "            X, y,\n",
      "            sample_weight=sample_weight,\n",
      "            check_input=check_input,\n",
      "            X_idx_sorted=X_idx_sorted)\n",
      "        return self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "print(inspect.getsource(DecisionTreeClassifier.fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need to keep digging.\n",
    "\n",
    "Hmmm, that is not very helpful. All it does is call its parent class's `fit()`. To dig into the method we need to determine what that parent class is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class DecisionTreeClassifier(ClassifierMixin, BaseDecisionTree):\n",
      "    \"\"\"A decision tree classifier.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(inspect.getsource(DecisionTreeClassifier)[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a `BaseDecisionTree`, so let's look up its `fit()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
      "            X_idx_sorted=None):\n",
      "\n",
      "        random_state = check_random_state(self.random_state)\n",
      "\n",
      "        if self.ccp_alpha < 0.0:\n",
      "            raise ValueError(\"ccp_alpha must be greater than or equal to 0\")\n",
      "\n",
      "        if check_input:\n",
      "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
      "            y = check_array(y, ensure_2d=False, dtype=None)\n",
      "            if issparse(X):\n",
      "                X.sort_indices()\n",
      "\n",
      "                if X.indices.dtype != np.intc or X.indptr.dtype != np.intc:\n",
      "                    raise ValueError(\"No support for np.int64 index based \"\n",
      "                                     \"sparse matrices\")\n",
      "\n",
      "        # Determine output settings\n",
      "        n_samples, self.n_features_ = X.shape\n",
      "        is_classification = is_classifier(self)\n",
      "\n",
      "        y = np.atleast_1d(y)\n",
      "        expanded_class_weight = None\n",
      "\n",
      "        if y.ndim == 1:\n",
      "            # reshape is necessary to preserve the data contiguity against vs\n",
      "            # [:, np.newaxis] that does not.\n",
      "            y = np.reshape(y, (-1, 1))\n",
      "\n",
      "        self.n_outputs_ = y.shape[1]\n",
      "\n",
      "        if is_classification:\n",
      "            check_classification_targets(y)\n",
      "            y = np.copy(y)\n",
      "\n",
      "            self.classes_ = []\n",
      "            self.n_classes_ = []\n",
      "\n",
      "            if self.class_weight is not None:\n",
      "                y_original = np.copy(y)\n",
      "\n",
      "            y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "            for k in range(self.n_outputs_):\n",
      "                classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
      "                                                       return_inverse=True)\n",
      "                self.classes_.append(classes_k)\n",
      "                self.n_classes_.append(classes_k.shape[0])\n",
      "            y = y_encoded\n",
      "\n",
      "            if self.class_weight is not None:\n",
      "                expanded_class_weight = compute_sample_weight(\n",
      "                    self.class_weight, y_original)\n",
      "\n",
      "            self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
      "\n",
      "        if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
      "            y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\n",
      "        # Check parameters\n",
      "        max_depth = (np.iinfo(np.int32).max if self.max_depth is None\n",
      "                     else self.max_depth)\n",
      "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
      "                          else self.max_leaf_nodes)\n",
      "\n",
      "        if isinstance(self.min_samples_leaf, numbers.Integral):\n",
      "            if not 1 <= self.min_samples_leaf:\n",
      "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
      "                                 \"or in (0, 0.5], got %s\"\n",
      "                                 % self.min_samples_leaf)\n",
      "            min_samples_leaf = self.min_samples_leaf\n",
      "        else:  # float\n",
      "            if not 0. < self.min_samples_leaf <= 0.5:\n",
      "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
      "                                 \"or in (0, 0.5], got %s\"\n",
      "                                 % self.min_samples_leaf)\n",
      "            min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
      "\n",
      "        if isinstance(self.min_samples_split, numbers.Integral):\n",
      "            if not 2 <= self.min_samples_split:\n",
      "                raise ValueError(\"min_samples_split must be an integer \"\n",
      "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "                                 \"got the integer %s\"\n",
      "                                 % self.min_samples_split)\n",
      "            min_samples_split = self.min_samples_split\n",
      "        else:  # float\n",
      "            if not 0. < self.min_samples_split <= 1.:\n",
      "                raise ValueError(\"min_samples_split must be an integer \"\n",
      "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "                                 \"got the float %s\"\n",
      "                                 % self.min_samples_split)\n",
      "            min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "            min_samples_split = max(2, min_samples_split)\n",
      "\n",
      "        min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "        if isinstance(self.max_features, str):\n",
      "            if self.max_features == \"auto\":\n",
      "                if is_classification:\n",
      "                    max_features = max(1, int(np.sqrt(self.n_features_)))\n",
      "                else:\n",
      "                    max_features = self.n_features_\n",
      "            elif self.max_features == \"sqrt\":\n",
      "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
      "            elif self.max_features == \"log2\":\n",
      "                max_features = max(1, int(np.log2(self.n_features_)))\n",
      "            else:\n",
      "                raise ValueError(\"Invalid value for max_features. \"\n",
      "                                 \"Allowed string values are 'auto', \"\n",
      "                                 \"'sqrt' or 'log2'.\")\n",
      "        elif self.max_features is None:\n",
      "            max_features = self.n_features_\n",
      "        elif isinstance(self.max_features, numbers.Integral):\n",
      "            max_features = self.max_features\n",
      "        else:  # float\n",
      "            if self.max_features > 0.0:\n",
      "                max_features = max(1,\n",
      "                                   int(self.max_features * self.n_features_))\n",
      "            else:\n",
      "                max_features = 0\n",
      "\n",
      "        self.max_features_ = max_features\n",
      "\n",
      "        if len(y) != n_samples:\n",
      "            raise ValueError(\"Number of labels=%d does not match \"\n",
      "                             \"number of samples=%d\" % (len(y), n_samples))\n",
      "        if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
      "            raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "        if max_depth <= 0:\n",
      "            raise ValueError(\"max_depth must be greater than zero. \")\n",
      "        if not (0 < max_features <= self.n_features_):\n",
      "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "        if not isinstance(max_leaf_nodes, numbers.Integral):\n",
      "            raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "                             \"%r\" % max_leaf_nodes)\n",
      "        if -1 < max_leaf_nodes < 2:\n",
      "            raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
      "                              \"or larger than 1\").format(max_leaf_nodes))\n",
      "\n",
      "        if sample_weight is not None:\n",
      "            sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\n",
      "        if expanded_class_weight is not None:\n",
      "            if sample_weight is not None:\n",
      "                sample_weight = sample_weight * expanded_class_weight\n",
      "            else:\n",
      "                sample_weight = expanded_class_weight\n",
      "\n",
      "        # Set min_weight_leaf from min_weight_fraction_leaf\n",
      "        if sample_weight is None:\n",
      "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
      "                               n_samples)\n",
      "        else:\n",
      "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
      "                               np.sum(sample_weight))\n",
      "\n",
      "        if self.min_impurity_split is not None:\n",
      "            warnings.warn(\"The min_impurity_split parameter is deprecated. \"\n",
      "                          \"Its default value will change from 1e-7 to 0 in \"\n",
      "                          \"version 0.23, and it will be removed in 0.25. \"\n",
      "                          \"Use the min_impurity_decrease parameter instead.\",\n",
      "                          FutureWarning)\n",
      "            min_impurity_split = self.min_impurity_split\n",
      "        else:\n",
      "            min_impurity_split = 1e-7\n",
      "\n",
      "        if min_impurity_split < 0.:\n",
      "            raise ValueError(\"min_impurity_split must be greater than \"\n",
      "                             \"or equal to 0\")\n",
      "\n",
      "        if self.min_impurity_decrease < 0.:\n",
      "            raise ValueError(\"min_impurity_decrease must be greater than \"\n",
      "                             \"or equal to 0\")\n",
      "\n",
      "        if self.presort != 'deprecated':\n",
      "            warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "                          \"effect. It will be removed in v0.24. You can \"\n",
      "                          \"suppress this warning by not passing any value \"\n",
      "                          \"to the 'presort' parameter.\",\n",
      "                          FutureWarning)\n",
      "\n",
      "        # Build tree\n",
      "        criterion = self.criterion\n",
      "        if not isinstance(criterion, Criterion):\n",
      "            if is_classification:\n",
      "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "                                                         self.n_classes_)\n",
      "            else:\n",
      "                criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "                                                         n_samples)\n",
      "\n",
      "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
      "\n",
      "        splitter = self.splitter\n",
      "        if not isinstance(self.splitter, Splitter):\n",
      "            splitter = SPLITTERS[self.splitter](criterion,\n",
      "                                                self.max_features_,\n",
      "                                                min_samples_leaf,\n",
      "                                                min_weight_leaf,\n",
      "                                                random_state)\n",
      "\n",
      "        if is_classifier(self):\n",
      "            self.tree_ = Tree(self.n_features_,\n",
      "                              self.n_classes_, self.n_outputs_)\n",
      "        else:\n",
      "            self.tree_ = Tree(self.n_features_,\n",
      "                              # TODO: tree should't need this in this case\n",
      "                              np.array([1] * self.n_outputs_, dtype=np.intp),\n",
      "                              self.n_outputs_)\n",
      "\n",
      "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
      "        if max_leaf_nodes < 0:\n",
      "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
      "                                            min_samples_leaf,\n",
      "                                            min_weight_leaf,\n",
      "                                            max_depth,\n",
      "                                            self.min_impurity_decrease,\n",
      "                                            min_impurity_split)\n",
      "        else:\n",
      "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
      "                                           min_samples_leaf,\n",
      "                                           min_weight_leaf,\n",
      "                                           max_depth,\n",
      "                                           max_leaf_nodes,\n",
      "                                           self.min_impurity_decrease,\n",
      "                                           min_impurity_split)\n",
      "\n",
      "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "\n",
      "        if self.n_outputs_ == 1 and is_classifier(self):\n",
      "            self.n_classes_ = self.n_classes_[0]\n",
      "            self.classes_ = self.classes_[0]\n",
      "\n",
      "        self._prune_tree()\n",
      "\n",
      "        return self\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import BaseDecisionTree\n",
    "print(inspect.getsource(BaseDecisionTree.fit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify `BaseDecisionTree.fit()`.\n",
    "\n",
    "That is a long, ugly method. To be able to dive in as a monkey patch, we will copy the text above and insert a line to see that we can interact with it. We insert the `print(f'PATCH: n_samples={n_samples}')` code below. Execute the cell for this new fit function to take hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(self, X, y, sample_weight=None, check_input=True,\n",
    "        X_idx_sorted=None):\n",
    "\n",
    "    random_state = check_random_state(self.random_state)\n",
    "\n",
    "    if self.ccp_alpha < 0.0:\n",
    "        raise ValueError(\"ccp_alpha must be greater than or equal to 0\")\n",
    "\n",
    "    if check_input:\n",
    "        X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
    "        y = check_array(y, ensure_2d=False, dtype=None)\n",
    "        if issparse(X):\n",
    "            X.sort_indices()\n",
    "\n",
    "            if X.indices.dtype != np.intc or X.indptr.dtype != np.intc:\n",
    "                raise ValueError(\"No support for np.int64 index based \"\n",
    "                                 \"sparse matrices\")\n",
    "\n",
    "    # Determine output settings\n",
    "    n_samples, self.n_features_ = X.shape\n",
    "    print(f'PATCH: n_samples={n_samples}')\n",
    "    is_classification = is_classifier(self)\n",
    "\n",
    "    y = np.atleast_1d(y)\n",
    "    expanded_class_weight = None\n",
    "\n",
    "    if y.ndim == 1:\n",
    "        # reshape is necessary to preserve the data contiguity against vs\n",
    "        # [:, np.newaxis] that does not.\n",
    "        y = np.reshape(y, (-1, 1))\n",
    "\n",
    "    self.n_outputs_ = y.shape[1]\n",
    "\n",
    "    if is_classification:\n",
    "        check_classification_targets(y)\n",
    "        y = np.copy(y)\n",
    "\n",
    "        self.classes_ = []\n",
    "        self.n_classes_ = []\n",
    "\n",
    "        if self.class_weight is not None:\n",
    "            y_original = np.copy(y)\n",
    "\n",
    "        y_encoded = np.zeros(y.shape, dtype=np.int)\n",
    "        for k in range(self.n_outputs_):\n",
    "            classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
    "                                                   return_inverse=True)\n",
    "            self.classes_.append(classes_k)\n",
    "            self.n_classes_.append(classes_k.shape[0])\n",
    "        y = y_encoded\n",
    "\n",
    "        if self.class_weight is not None:\n",
    "            expanded_class_weight = compute_sample_weight(\n",
    "                self.class_weight, y_original)\n",
    "\n",
    "        self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
    "\n",
    "    if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
    "        y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
    "\n",
    "    # Check parameters\n",
    "    max_depth = (np.iinfo(np.int32).max if self.max_depth is None\n",
    "                 else self.max_depth)\n",
    "    max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
    "                      else self.max_leaf_nodes)\n",
    "\n",
    "    if isinstance(self.min_samples_leaf, numbers.Integral):\n",
    "        if not 1 <= self.min_samples_leaf:\n",
    "            raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                             \"or in (0, 0.5], got %s\"\n",
    "                             % self.min_samples_leaf)\n",
    "        min_samples_leaf = self.min_samples_leaf\n",
    "    else:  # float\n",
    "        if not 0. < self.min_samples_leaf <= 0.5:\n",
    "            raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
    "                             \"or in (0, 0.5], got %s\"\n",
    "                             % self.min_samples_leaf)\n",
    "        min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
    "\n",
    "    if isinstance(self.min_samples_split, numbers.Integral):\n",
    "        if not 2 <= self.min_samples_split:\n",
    "            raise ValueError(\"min_samples_split must be an integer \"\n",
    "                             \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                             \"got the integer %s\"\n",
    "                             % self.min_samples_split)\n",
    "        min_samples_split = self.min_samples_split\n",
    "    else:  # float\n",
    "        if not 0. < self.min_samples_split <= 1.:\n",
    "            raise ValueError(\"min_samples_split must be an integer \"\n",
    "                             \"greater than 1 or a float in (0.0, 1.0]; \"\n",
    "                             \"got the float %s\"\n",
    "                             % self.min_samples_split)\n",
    "        min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
    "        min_samples_split = max(2, min_samples_split)\n",
    "\n",
    "    min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
    "\n",
    "    if isinstance(self.max_features, str):\n",
    "        if self.max_features == \"auto\":\n",
    "            if is_classification:\n",
    "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "            else:\n",
    "                max_features = self.n_features_\n",
    "        elif self.max_features == \"sqrt\":\n",
    "            max_features = max(1, int(np.sqrt(self.n_features_)))\n",
    "        elif self.max_features == \"log2\":\n",
    "            max_features = max(1, int(np.log2(self.n_features_)))\n",
    "        else:\n",
    "            raise ValueError(\"Invalid value for max_features. \"\n",
    "                             \"Allowed string values are 'auto', \"\n",
    "                             \"'sqrt' or 'log2'.\")\n",
    "    elif self.max_features is None:\n",
    "        max_features = self.n_features_\n",
    "    elif isinstance(self.max_features, numbers.Integral):\n",
    "        max_features = self.max_features\n",
    "    else:  # float\n",
    "        if self.max_features > 0.0:\n",
    "            max_features = max(1,\n",
    "                               int(self.max_features * self.n_features_))\n",
    "        else:\n",
    "            max_features = 0\n",
    "\n",
    "    self.max_features_ = max_features\n",
    "\n",
    "    if len(y) != n_samples:\n",
    "        raise ValueError(\"Number of labels=%d does not match \"\n",
    "                         \"number of samples=%d\" % (len(y), n_samples))\n",
    "    if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
    "        raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
    "    if max_depth <= 0:\n",
    "        raise ValueError(\"max_depth must be greater than zero. \")\n",
    "    if not (0 < max_features <= self.n_features_):\n",
    "        raise ValueError(\"max_features must be in (0, n_features]\")\n",
    "    if not isinstance(max_leaf_nodes, numbers.Integral):\n",
    "        raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
    "                         \"%r\" % max_leaf_nodes)\n",
    "    if -1 < max_leaf_nodes < 2:\n",
    "        raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
    "                          \"or larger than 1\").format(max_leaf_nodes))\n",
    "\n",
    "    if sample_weight is not None:\n",
    "        sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
    "\n",
    "    if expanded_class_weight is not None:\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = sample_weight * expanded_class_weight\n",
    "        else:\n",
    "            sample_weight = expanded_class_weight\n",
    "\n",
    "    # Set min_weight_leaf from min_weight_fraction_leaf\n",
    "    if sample_weight is None:\n",
    "        min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                           n_samples)\n",
    "    else:\n",
    "        min_weight_leaf = (self.min_weight_fraction_leaf *\n",
    "                           np.sum(sample_weight))\n",
    "\n",
    "    if self.min_impurity_split is not None:\n",
    "        warnings.warn(\"The min_impurity_split parameter is deprecated. \"\n",
    "                      \"Its default value will change from 1e-7 to 0 in \"\n",
    "                      \"version 0.23, and it will be removed in 0.25. \"\n",
    "                      \"Use the min_impurity_decrease parameter instead.\",\n",
    "                      FutureWarning)\n",
    "        min_impurity_split = self.min_impurity_split\n",
    "    else:\n",
    "        min_impurity_split = 1e-7\n",
    "\n",
    "    if min_impurity_split < 0.:\n",
    "        raise ValueError(\"min_impurity_split must be greater than \"\n",
    "                         \"or equal to 0\")\n",
    "\n",
    "    if self.min_impurity_decrease < 0.:\n",
    "        raise ValueError(\"min_impurity_decrease must be greater than \"\n",
    "                         \"or equal to 0\")\n",
    "\n",
    "    if self.presort != 'deprecated':\n",
    "        warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
    "                      \"effect. It will be removed in v0.24. You can \"\n",
    "                      \"suppress this warning by not passing any value \"\n",
    "                      \"to the 'presort' parameter.\",\n",
    "                      FutureWarning)\n",
    "\n",
    "    # Build tree\n",
    "    criterion = self.criterion\n",
    "    if not isinstance(criterion, Criterion):\n",
    "        if is_classification:\n",
    "            criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
    "                                                     self.n_classes_)\n",
    "        else:\n",
    "            criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
    "                                                     n_samples)\n",
    "\n",
    "    SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
    "\n",
    "    splitter = self.splitter\n",
    "    if not isinstance(self.splitter, Splitter):\n",
    "        splitter = SPLITTERS[self.splitter](criterion,\n",
    "                                            self.max_features_,\n",
    "                                            min_samples_leaf,\n",
    "                                            min_weight_leaf,\n",
    "                                            random_state)\n",
    "\n",
    "    if is_classifier(self):\n",
    "        self.tree_ = Tree(self.n_features_,\n",
    "                          self.n_classes_, self.n_outputs_)\n",
    "    else:\n",
    "        self.tree_ = Tree(self.n_features_,\n",
    "                          # TODO: tree should't need this in this case\n",
    "                          np.array([1] * self.n_outputs_, dtype=np.intp),\n",
    "                          self.n_outputs_)\n",
    "\n",
    "    # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
    "    if max_leaf_nodes < 0:\n",
    "        builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                        min_samples_leaf,\n",
    "                                        min_weight_leaf,\n",
    "                                        max_depth,\n",
    "                                        self.min_impurity_decrease,\n",
    "                                        min_impurity_split)\n",
    "    else:\n",
    "        builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
    "                                       min_samples_leaf,\n",
    "                                       min_weight_leaf,\n",
    "                                       max_depth,\n",
    "                                       max_leaf_nodes,\n",
    "                                       self.min_impurity_decrease,\n",
    "                                       min_impurity_split)\n",
    "\n",
    "    builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
    "\n",
    "    if self.n_outputs_ == 1 and is_classifier(self):\n",
    "        self.n_classes_ = self.n_classes_[0]\n",
    "        self.classes_ = self.classes_[0]\n",
    "\n",
    "    self._prune_tree()\n",
    "\n",
    "    return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply it as a patch.\n",
    "\n",
    "Let's try applying the patch to our DecisionTreeClassifier object. Note that we are replacing the `super().fit()` call that DecisionTreeClassifier usually performs with this one that we borrowed from `BaseDecisionTree`.\n",
    "\n",
    "> Note: This will raise a NameError that we will deal with next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_random_state' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-1eb3de177638>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# Apply the patch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Call the method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-b6408c634ae4>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m      2\u001b[0m         X_idx_sorted=None):\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mccp_alpha\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_random_state' is not defined"
     ]
    }
   ],
   "source": [
    "clf.fit = types.MethodType(fit, clf)   # Apply the patch\n",
    "clf.fit(iris.data, iris.target)  # Call the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with imports.\n",
    "\n",
    "The *NameError* caused above is throwing an error because the first line of our patch is calling `check_random_state()`, which is properly defined within the context of the `BaseDecisionTree` object, but isn't here in our space.\n",
    "\n",
    "As lengthy as this function is, there are likely several similar dependencies. Since `BaseDecisionTree` has its necessary imports and definitions, let's look at its source file. `inspect.getsourcefile()` tells us where it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/sklearn/tree/_classes.py'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inspect.getsourcefile(BaseDecisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "View it.\n",
    "\n",
    "(Given that this is a public repo, we can also find the source code at https://github.com/scikit-learn/scikit-learn/blob/0fb307bf39bbdacd6ed713c00724f8f871d60370/sklearn/tree/_classes.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"\"\"\n",
      "This module gathers tree-based methods, including decision, regression and\n",
      "randomized trees. Single and multi-output problems are both handled.\n",
      "\"\"\"\n",
      "\n",
      "# Authors: Gilles Louppe <g.louppe@gmail.com>\n",
      "#          Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
      "#          Brian Holt <bdholt1@gmail.com>\n",
      "#          Noel Dawe <noel@dawe.me>\n",
      "#          Satrajit Gosh <satrajit.ghosh@gmail.com>\n",
      "#          Joly Arnaud <arnaud.v.joly@gmail.com>\n",
      "#          Fares Hedayati <fares.hedayati@gmail.com>\n",
      "#          Nelson Liu <nelson@nelsonliu.me>\n",
      "#\n",
      "# License: BSD 3 clause\n",
      "\n",
      "import numbers\n",
      "import warnings\n",
      "from abc import ABCMeta\n",
      "from abc import abstractmethod\n",
      "from math import ceil\n",
      "\n",
      "import numpy as np\n",
      "from scipy.sparse import issparse\n",
      "\n",
      "from ..base import BaseEstimator\n",
      "from ..base import ClassifierMixin\n",
      "from ..base import clone\n",
      "from ..base import RegressorMixin\n",
      "from ..base import is_classifier\n",
      "from ..base import MultiOutputMixin\n",
      "from ..utils import Bunch\n",
      "from ..utils import check_array\n",
      "from ..utils import check_random_state\n",
      "from ..utils.validation import _check_sample_weight\n",
      "from ..utils import compute_sample_weight\n",
      "from ..utils.multiclass import check_classification_targets\n",
      "from ..utils.validation import check_is_fitted\n",
      "\n",
      "from ._criterion import Criterion\n",
      "from ._splitter import Splitter\n",
      "from ._tree import DepthFirstTreeBuilder\n",
      "from ._tree import BestFirstTreeBuilder\n",
      "from ._tree import Tree\n",
      "from ._tree import _build_pruned_tree_ccp\n",
      "from ._tree import ccp_pruning_path\n",
      "from . import _tree, _splitter, _criterion\n",
      "\n",
      "__all__ = [\"DecisionTreeClassifier\",\n",
      "           \"DecisionTreeRegressor\",\n",
      "           \"ExtraTreeClassifier\",\n",
      "           \"ExtraTreeRegressor\"]\n",
      "\n",
      "\n",
      "# =============================================================================\n",
      "# Types and constants\n",
      "# =============================================================================\n",
      "\n",
      "DTYPE = _tree.DTYPE\n",
      "DOUBLE = _tree.DOUBLE\n",
      "\n",
      "CRITERIA_CLF = {\"gini\": _criterion.Gini, \"entropy\": _criterion.Entropy}\n",
      "CRITERIA_REG = {\"mse\": _criterion.MSE, \"friedman_mse\": _criterion.FriedmanMSE,\n",
      "                \"mae\": _criterion.MAE}\n",
      "\n",
      "DENSE_SPLITTERS = {\"best\": _splitter.BestSplitter,\n",
      "                   \"random\": _splitter.RandomSplitter}\n",
      "\n",
      "SPARSE_SPLITTERS = {\"best\": _splitter.BestSparseSplitter,\n",
      "                    \"random\": _splitter.RandomSparseSplitter}\n",
      "\n",
      "# =============================================================================\n",
      "# Base decision tree\n",
      "# =============================================================================\n",
      "\n",
      "\n",
      "class BaseDecisionTree(MultiOutputMixin, BaseEstimator, metaclass=ABCMeta):\n",
      "    \"\"\"Base class for decision trees.\n",
      "\n",
      "    Warning: This class should not be used directly.\n",
      "    Use derived classes instead.\n",
      "    \"\"\"\n",
      "\n",
      "    @abstractmethod\n",
      "    def __init__(self,\n",
      "                 criterion,\n",
      "                 splitter,\n",
      "                 max_depth,\n",
      "                 min_samples_split,\n",
      "                 min_samples_leaf,\n",
      "                 min_weight_fraction_leaf,\n",
      "                 max_features,\n",
      "                 max_leaf_nodes,\n",
      "                 random_state,\n",
      "                 min_impurity_decrease,\n",
      "                 min_impurity_split,\n",
      "                 class_weight=None,\n",
      "                 presort='deprecated',\n",
      "                 ccp_alpha=0.0):\n",
      "        self.criterion = criterion\n",
      "        self.splitter = splitter\n",
      "        self.max_depth = max_depth\n",
      "        self.min_samples_split = min_samples_split\n",
      "        self.min_samples_leaf = min_samples_leaf\n",
      "        self.min_weight_fraction_leaf = min_weight_fraction_leaf\n",
      "        self.max_features = max_features\n",
      "        self.random_state = random_state\n",
      "        self.max_leaf_nodes = max_leaf_nodes\n",
      "        self.min_impurity_decrease = min_impurity_decrease\n",
      "        self.min_impurity_split = min_impurity_split\n",
      "        self.class_weight = class_weight\n",
      "        self.presort = presort\n",
      "        self.ccp_alpha = ccp_alpha\n",
      "\n",
      "    def get_depth(self):\n",
      "        \"\"\"Return the depth of the decision tree.\n",
      "\n",
      "        The depth of a tree is the maximum distance between the root\n",
      "        and any leaf.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self.tree_.max_depth : int\n",
      "            The maximum depth of the tree.\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "        return self.tree_.max_depth\n",
      "\n",
      "    def get_n_leaves(self):\n",
      "        \"\"\"Return the number of leaves of the decision tree.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self.tree_.n_leaves : int\n",
      "            Number of leaves.\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "        return self.tree_.n_leaves\n",
      "\n",
      "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
      "            X_idx_sorted=None):\n",
      "\n",
      "        random_state = check_random_state(self.random_state)\n",
      "\n",
      "        if self.ccp_alpha < 0.0:\n",
      "            raise ValueError(\"ccp_alpha must be greater than or equal to 0\")\n",
      "\n",
      "        if check_input:\n",
      "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csc\")\n",
      "            y = check_array(y, ensure_2d=False, dtype=None)\n",
      "            if issparse(X):\n",
      "                X.sort_indices()\n",
      "\n",
      "                if X.indices.dtype != np.intc or X.indptr.dtype != np.intc:\n",
      "                    raise ValueError(\"No support for np.int64 index based \"\n",
      "                                     \"sparse matrices\")\n",
      "\n",
      "        # Determine output settings\n",
      "        n_samples, self.n_features_ = X.shape\n",
      "        is_classification = is_classifier(self)\n",
      "\n",
      "        y = np.atleast_1d(y)\n",
      "        expanded_class_weight = None\n",
      "\n",
      "        if y.ndim == 1:\n",
      "            # reshape is necessary to preserve the data contiguity against vs\n",
      "            # [:, np.newaxis] that does not.\n",
      "            y = np.reshape(y, (-1, 1))\n",
      "\n",
      "        self.n_outputs_ = y.shape[1]\n",
      "\n",
      "        if is_classification:\n",
      "            check_classification_targets(y)\n",
      "            y = np.copy(y)\n",
      "\n",
      "            self.classes_ = []\n",
      "            self.n_classes_ = []\n",
      "\n",
      "            if self.class_weight is not None:\n",
      "                y_original = np.copy(y)\n",
      "\n",
      "            y_encoded = np.zeros(y.shape, dtype=np.int)\n",
      "            for k in range(self.n_outputs_):\n",
      "                classes_k, y_encoded[:, k] = np.unique(y[:, k],\n",
      "                                                       return_inverse=True)\n",
      "                self.classes_.append(classes_k)\n",
      "                self.n_classes_.append(classes_k.shape[0])\n",
      "            y = y_encoded\n",
      "\n",
      "            if self.class_weight is not None:\n",
      "                expanded_class_weight = compute_sample_weight(\n",
      "                    self.class_weight, y_original)\n",
      "\n",
      "            self.n_classes_ = np.array(self.n_classes_, dtype=np.intp)\n",
      "\n",
      "        if getattr(y, \"dtype\", None) != DOUBLE or not y.flags.contiguous:\n",
      "            y = np.ascontiguousarray(y, dtype=DOUBLE)\n",
      "\n",
      "        # Check parameters\n",
      "        max_depth = (np.iinfo(np.int32).max if self.max_depth is None\n",
      "                     else self.max_depth)\n",
      "        max_leaf_nodes = (-1 if self.max_leaf_nodes is None\n",
      "                          else self.max_leaf_nodes)\n",
      "\n",
      "        if isinstance(self.min_samples_leaf, numbers.Integral):\n",
      "            if not 1 <= self.min_samples_leaf:\n",
      "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
      "                                 \"or in (0, 0.5], got %s\"\n",
      "                                 % self.min_samples_leaf)\n",
      "            min_samples_leaf = self.min_samples_leaf\n",
      "        else:  # float\n",
      "            if not 0. < self.min_samples_leaf <= 0.5:\n",
      "                raise ValueError(\"min_samples_leaf must be at least 1 \"\n",
      "                                 \"or in (0, 0.5], got %s\"\n",
      "                                 % self.min_samples_leaf)\n",
      "            min_samples_leaf = int(ceil(self.min_samples_leaf * n_samples))\n",
      "\n",
      "        if isinstance(self.min_samples_split, numbers.Integral):\n",
      "            if not 2 <= self.min_samples_split:\n",
      "                raise ValueError(\"min_samples_split must be an integer \"\n",
      "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "                                 \"got the integer %s\"\n",
      "                                 % self.min_samples_split)\n",
      "            min_samples_split = self.min_samples_split\n",
      "        else:  # float\n",
      "            if not 0. < self.min_samples_split <= 1.:\n",
      "                raise ValueError(\"min_samples_split must be an integer \"\n",
      "                                 \"greater than 1 or a float in (0.0, 1.0]; \"\n",
      "                                 \"got the float %s\"\n",
      "                                 % self.min_samples_split)\n",
      "            min_samples_split = int(ceil(self.min_samples_split * n_samples))\n",
      "            min_samples_split = max(2, min_samples_split)\n",
      "\n",
      "        min_samples_split = max(min_samples_split, 2 * min_samples_leaf)\n",
      "\n",
      "        if isinstance(self.max_features, str):\n",
      "            if self.max_features == \"auto\":\n",
      "                if is_classification:\n",
      "                    max_features = max(1, int(np.sqrt(self.n_features_)))\n",
      "                else:\n",
      "                    max_features = self.n_features_\n",
      "            elif self.max_features == \"sqrt\":\n",
      "                max_features = max(1, int(np.sqrt(self.n_features_)))\n",
      "            elif self.max_features == \"log2\":\n",
      "                max_features = max(1, int(np.log2(self.n_features_)))\n",
      "            else:\n",
      "                raise ValueError(\"Invalid value for max_features. \"\n",
      "                                 \"Allowed string values are 'auto', \"\n",
      "                                 \"'sqrt' or 'log2'.\")\n",
      "        elif self.max_features is None:\n",
      "            max_features = self.n_features_\n",
      "        elif isinstance(self.max_features, numbers.Integral):\n",
      "            max_features = self.max_features\n",
      "        else:  # float\n",
      "            if self.max_features > 0.0:\n",
      "                max_features = max(1,\n",
      "                                   int(self.max_features * self.n_features_))\n",
      "            else:\n",
      "                max_features = 0\n",
      "\n",
      "        self.max_features_ = max_features\n",
      "\n",
      "        if len(y) != n_samples:\n",
      "            raise ValueError(\"Number of labels=%d does not match \"\n",
      "                             \"number of samples=%d\" % (len(y), n_samples))\n",
      "        if not 0 <= self.min_weight_fraction_leaf <= 0.5:\n",
      "            raise ValueError(\"min_weight_fraction_leaf must in [0, 0.5]\")\n",
      "        if max_depth <= 0:\n",
      "            raise ValueError(\"max_depth must be greater than zero. \")\n",
      "        if not (0 < max_features <= self.n_features_):\n",
      "            raise ValueError(\"max_features must be in (0, n_features]\")\n",
      "        if not isinstance(max_leaf_nodes, numbers.Integral):\n",
      "            raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "                             \"%r\" % max_leaf_nodes)\n",
      "        if -1 < max_leaf_nodes < 2:\n",
      "            raise ValueError((\"max_leaf_nodes {0} must be either None \"\n",
      "                              \"or larger than 1\").format(max_leaf_nodes))\n",
      "\n",
      "        if sample_weight is not None:\n",
      "            sample_weight = _check_sample_weight(sample_weight, X, DOUBLE)\n",
      "\n",
      "        if expanded_class_weight is not None:\n",
      "            if sample_weight is not None:\n",
      "                sample_weight = sample_weight * expanded_class_weight\n",
      "            else:\n",
      "                sample_weight = expanded_class_weight\n",
      "\n",
      "        # Set min_weight_leaf from min_weight_fraction_leaf\n",
      "        if sample_weight is None:\n",
      "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
      "                               n_samples)\n",
      "        else:\n",
      "            min_weight_leaf = (self.min_weight_fraction_leaf *\n",
      "                               np.sum(sample_weight))\n",
      "\n",
      "        if self.min_impurity_split is not None:\n",
      "            warnings.warn(\"The min_impurity_split parameter is deprecated. \"\n",
      "                          \"Its default value will change from 1e-7 to 0 in \"\n",
      "                          \"version 0.23, and it will be removed in 0.25. \"\n",
      "                          \"Use the min_impurity_decrease parameter instead.\",\n",
      "                          FutureWarning)\n",
      "            min_impurity_split = self.min_impurity_split\n",
      "        else:\n",
      "            min_impurity_split = 1e-7\n",
      "\n",
      "        if min_impurity_split < 0.:\n",
      "            raise ValueError(\"min_impurity_split must be greater than \"\n",
      "                             \"or equal to 0\")\n",
      "\n",
      "        if self.min_impurity_decrease < 0.:\n",
      "            raise ValueError(\"min_impurity_decrease must be greater than \"\n",
      "                             \"or equal to 0\")\n",
      "\n",
      "        if self.presort != 'deprecated':\n",
      "            warnings.warn(\"The parameter 'presort' is deprecated and has no \"\n",
      "                          \"effect. It will be removed in v0.24. You can \"\n",
      "                          \"suppress this warning by not passing any value \"\n",
      "                          \"to the 'presort' parameter.\",\n",
      "                          FutureWarning)\n",
      "\n",
      "        # Build tree\n",
      "        criterion = self.criterion\n",
      "        if not isinstance(criterion, Criterion):\n",
      "            if is_classification:\n",
      "                criterion = CRITERIA_CLF[self.criterion](self.n_outputs_,\n",
      "                                                         self.n_classes_)\n",
      "            else:\n",
      "                criterion = CRITERIA_REG[self.criterion](self.n_outputs_,\n",
      "                                                         n_samples)\n",
      "\n",
      "        SPLITTERS = SPARSE_SPLITTERS if issparse(X) else DENSE_SPLITTERS\n",
      "\n",
      "        splitter = self.splitter\n",
      "        if not isinstance(self.splitter, Splitter):\n",
      "            splitter = SPLITTERS[self.splitter](criterion,\n",
      "                                                self.max_features_,\n",
      "                                                min_samples_leaf,\n",
      "                                                min_weight_leaf,\n",
      "                                                random_state)\n",
      "\n",
      "        if is_classifier(self):\n",
      "            self.tree_ = Tree(self.n_features_,\n",
      "                              self.n_classes_, self.n_outputs_)\n",
      "        else:\n",
      "            self.tree_ = Tree(self.n_features_,\n",
      "                              # TODO: tree should't need this in this case\n",
      "                              np.array([1] * self.n_outputs_, dtype=np.intp),\n",
      "                              self.n_outputs_)\n",
      "\n",
      "        # Use BestFirst if max_leaf_nodes given; use DepthFirst otherwise\n",
      "        if max_leaf_nodes < 0:\n",
      "            builder = DepthFirstTreeBuilder(splitter, min_samples_split,\n",
      "                                            min_samples_leaf,\n",
      "                                            min_weight_leaf,\n",
      "                                            max_depth,\n",
      "                                            self.min_impurity_decrease,\n",
      "                                            min_impurity_split)\n",
      "        else:\n",
      "            builder = BestFirstTreeBuilder(splitter, min_samples_split,\n",
      "                                           min_samples_leaf,\n",
      "                                           min_weight_leaf,\n",
      "                                           max_depth,\n",
      "                                           max_leaf_nodes,\n",
      "                                           self.min_impurity_decrease,\n",
      "                                           min_impurity_split)\n",
      "\n",
      "        builder.build(self.tree_, X, y, sample_weight, X_idx_sorted)\n",
      "\n",
      "        if self.n_outputs_ == 1 and is_classifier(self):\n",
      "            self.n_classes_ = self.n_classes_[0]\n",
      "            self.classes_ = self.classes_[0]\n",
      "\n",
      "        self._prune_tree()\n",
      "\n",
      "        return self\n",
      "\n",
      "    def _validate_X_predict(self, X, check_input):\n",
      "        \"\"\"Validate X whenever one tries to predict, apply, predict_proba\"\"\"\n",
      "        if check_input:\n",
      "            X = check_array(X, dtype=DTYPE, accept_sparse=\"csr\")\n",
      "            if issparse(X) and (X.indices.dtype != np.intc or\n",
      "                                X.indptr.dtype != np.intc):\n",
      "                raise ValueError(\"No support for np.int64 index based \"\n",
      "                                 \"sparse matrices\")\n",
      "\n",
      "        n_features = X.shape[1]\n",
      "        if self.n_features_ != n_features:\n",
      "            raise ValueError(\"Number of features of the model must \"\n",
      "                             \"match the input. Model n_features is %s and \"\n",
      "                             \"input n_features is %s \"\n",
      "                             % (self.n_features_, n_features))\n",
      "\n",
      "        return X\n",
      "\n",
      "    def predict(self, X, check_input=True):\n",
      "        \"\"\"Predict class or regression value for X.\n",
      "\n",
      "        For a classification model, the predicted class for each sample in X is\n",
      "        returned. For a regression model, the predicted value based on X is\n",
      "        returned.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The predicted classes, or the predict values.\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "        X = self._validate_X_predict(X, check_input)\n",
      "        proba = self.tree_.predict(X)\n",
      "        n_samples = X.shape[0]\n",
      "\n",
      "        # Classification\n",
      "        if is_classifier(self):\n",
      "            if self.n_outputs_ == 1:\n",
      "                return self.classes_.take(np.argmax(proba, axis=1), axis=0)\n",
      "\n",
      "            else:\n",
      "                class_type = self.classes_[0].dtype\n",
      "                predictions = np.zeros((n_samples, self.n_outputs_),\n",
      "                                       dtype=class_type)\n",
      "                for k in range(self.n_outputs_):\n",
      "                    predictions[:, k] = self.classes_[k].take(\n",
      "                        np.argmax(proba[:, k], axis=1),\n",
      "                        axis=0)\n",
      "\n",
      "                return predictions\n",
      "\n",
      "        # Regression\n",
      "        else:\n",
      "            if self.n_outputs_ == 1:\n",
      "                return proba[:, 0]\n",
      "\n",
      "            else:\n",
      "                return proba[:, :, 0]\n",
      "\n",
      "    def apply(self, X, check_input=True):\n",
      "        \"\"\"Return the index of the leaf that each sample is predicted as.\n",
      "\n",
      "        .. versionadded:: 0.17\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        X_leaves : array-like of shape (n_samples,)\n",
      "            For each datapoint x in X, return the index of the leaf x\n",
      "            ends up in. Leaves are numbered within\n",
      "            ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      "            numbering.\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "        X = self._validate_X_predict(X, check_input)\n",
      "        return self.tree_.apply(X)\n",
      "\n",
      "    def decision_path(self, X, check_input=True):\n",
      "        \"\"\"Return the decision path in the tree.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      "            Return a node indicator CSR matrix where non zero elements\n",
      "            indicates that the samples goes through the nodes.\n",
      "        \"\"\"\n",
      "        X = self._validate_X_predict(X, check_input)\n",
      "        return self.tree_.decision_path(X)\n",
      "\n",
      "    def _prune_tree(self):\n",
      "        \"\"\"Prune tree using Minimal Cost-Complexity Pruning.\"\"\"\n",
      "        check_is_fitted(self)\n",
      "\n",
      "        if self.ccp_alpha < 0.0:\n",
      "            raise ValueError(\"ccp_alpha must be greater than or equal to 0\")\n",
      "\n",
      "        if self.ccp_alpha == 0.0:\n",
      "            return\n",
      "\n",
      "        # build pruned tree\n",
      "        if is_classifier(self):\n",
      "            n_classes = np.atleast_1d(self.n_classes_)\n",
      "            pruned_tree = Tree(self.n_features_, n_classes, self.n_outputs_)\n",
      "        else:\n",
      "            pruned_tree = Tree(self.n_features_,\n",
      "                               # TODO: the tree shouldn't need this param\n",
      "                               np.array([1] * self.n_outputs_, dtype=np.intp),\n",
      "                               self.n_outputs_)\n",
      "        _build_pruned_tree_ccp(pruned_tree, self.tree_, self.ccp_alpha)\n",
      "\n",
      "        self.tree_ = pruned_tree\n",
      "\n",
      "    def cost_complexity_pruning_path(self, X, y, sample_weight=None):\n",
      "        \"\"\"Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
      "\n",
      "        See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
      "        process.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (class labels) as integers or strings.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node. Splits are also\n",
      "            ignored if they would result in any single class carrying a\n",
      "            negative weight in either child node.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        ccp_path : Bunch\n",
      "            Dictionary-like object, with attributes:\n",
      "\n",
      "            ccp_alphas : ndarray\n",
      "                Effective alphas of subtree during pruning.\n",
      "\n",
      "            impurities : ndarray\n",
      "                Sum of the impurities of the subtree leaves for the\n",
      "                corresponding alpha value in ``ccp_alphas``.\n",
      "        \"\"\"\n",
      "        est = clone(self).set_params(ccp_alpha=0.0)\n",
      "        est.fit(X, y, sample_weight=sample_weight)\n",
      "        return Bunch(**ccp_pruning_path(est.tree_))\n",
      "\n",
      "    @property\n",
      "    def feature_importances_(self):\n",
      "        \"\"\"Return the feature importances.\n",
      "\n",
      "        The importance of a feature is computed as the (normalized) total\n",
      "        reduction of the criterion brought by that feature.\n",
      "        It is also known as the Gini importance.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        feature_importances_ : ndarray of shape (n_features,)\n",
      "            Normalized total reduction of criteria by feature\n",
      "            (Gini importance).\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "\n",
      "        return self.tree_.compute_feature_importances()\n",
      "\n",
      "\n",
      "# =============================================================================\n",
      "# Public estimators\n",
      "# =============================================================================\n",
      "\n",
      "class DecisionTreeClassifier(ClassifierMixin, BaseDecisionTree):\n",
      "    \"\"\"A decision tree classifier.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "\n",
      "    splitter : {\"best\", \"random\"}, default=\"best\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "            - If int, then consider `max_features` features at each split.\n",
      "            - If float, then `max_features` is a fraction and\n",
      "              `int(max_features * n_features)` features are considered at each\n",
      "              split.\n",
      "            - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"log2\", then `max_features=log2(n_features)`.\n",
      "            - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int or RandomState, default=None\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, default=1e-7\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "    class_weight : dict, list of dict or \"balanced\", default=None\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If None, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    presort : deprecated, default='deprecated'\n",
      "        This parameter is deprecated and will be removed in v0.24.\n",
      "\n",
      "        .. deprecated:: 0.22\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
      "        The classes labels (single output problem),\n",
      "        or a list of arrays of class labels (multi-output problem).\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The feature importances. The higher, the more important the\n",
      "        feature. The importance of a feature is computed as the (normalized)\n",
      "        total reduction of the criterion brought by that feature.  It is also\n",
      "        known as the Gini importance [4]_.\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_classes_ : int or list of int\n",
      "        The number of classes (for single output problems),\n",
      "        or a list containing the number of classes for each\n",
      "        output (for multi-output problems).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DecisionTreeRegressor : A decision tree regressor.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data and\n",
      "    ``max_features=n_features``, if the improvement of the criterion is\n",
      "    identical for several splits enumerated during the search of the best\n",
      "    split. To obtain a deterministic behaviour during fitting,\n",
      "    ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      "\n",
      "    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      "           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      "\n",
      "    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      "           Learning\", Springer, 2009.\n",
      "\n",
      "    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      "           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_iris\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> from sklearn.tree import DecisionTreeClassifier\n",
      "    >>> clf = DecisionTreeClassifier(random_state=0)\n",
      "    >>> iris = load_iris()\n",
      "    >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      "    ...                             # doctest: +SKIP\n",
      "    ...\n",
      "    array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      "            0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      "    \"\"\"\n",
      "    def __init__(self,\n",
      "                 criterion=\"gini\",\n",
      "                 splitter=\"best\",\n",
      "                 max_depth=None,\n",
      "                 min_samples_split=2,\n",
      "                 min_samples_leaf=1,\n",
      "                 min_weight_fraction_leaf=0.,\n",
      "                 max_features=None,\n",
      "                 random_state=None,\n",
      "                 max_leaf_nodes=None,\n",
      "                 min_impurity_decrease=0.,\n",
      "                 min_impurity_split=None,\n",
      "                 class_weight=None,\n",
      "                 presort='deprecated',\n",
      "                 ccp_alpha=0.0):\n",
      "        super().__init__(\n",
      "            criterion=criterion,\n",
      "            splitter=splitter,\n",
      "            max_depth=max_depth,\n",
      "            min_samples_split=min_samples_split,\n",
      "            min_samples_leaf=min_samples_leaf,\n",
      "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
      "            max_features=max_features,\n",
      "            max_leaf_nodes=max_leaf_nodes,\n",
      "            class_weight=class_weight,\n",
      "            random_state=random_state,\n",
      "            min_impurity_decrease=min_impurity_decrease,\n",
      "            min_impurity_split=min_impurity_split,\n",
      "            presort=presort,\n",
      "            ccp_alpha=ccp_alpha)\n",
      "\n",
      "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
      "            X_idx_sorted=None):\n",
      "        \"\"\"Build a decision tree classifier from the training set (X, y).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (class labels) as integers or strings.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node. Splits are also\n",
      "            ignored if they would result in any single class carrying a\n",
      "            negative weight in either child node.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        X_idx_sorted : array-like of shape (n_samples, n_features), \\\n",
      "                default=None\n",
      "            The indexes of the sorted training input samples. If many tree\n",
      "            are grown on the same dataset, this allows the ordering to be\n",
      "            cached between trees. If None, the data will be sorted here.\n",
      "            Don't use this parameter unless you know what to do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : DecisionTreeClassifier\n",
      "            Fitted estimator.\n",
      "        \"\"\"\n",
      "\n",
      "        super().fit(\n",
      "            X, y,\n",
      "            sample_weight=sample_weight,\n",
      "            check_input=check_input,\n",
      "            X_idx_sorted=X_idx_sorted)\n",
      "        return self\n",
      "\n",
      "    def predict_proba(self, X, check_input=True):\n",
      "        \"\"\"Predict class probabilities of the input samples X.\n",
      "\n",
      "        The predicted class probability is the fraction of samples of the same\n",
      "        class in a leaf.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\n",
      "        check_is_fitted(self)\n",
      "        X = self._validate_X_predict(X, check_input)\n",
      "        proba = self.tree_.predict(X)\n",
      "\n",
      "        if self.n_outputs_ == 1:\n",
      "            proba = proba[:, :self.n_classes_]\n",
      "            normalizer = proba.sum(axis=1)[:, np.newaxis]\n",
      "            normalizer[normalizer == 0.0] = 1.0\n",
      "            proba /= normalizer\n",
      "\n",
      "            return proba\n",
      "\n",
      "        else:\n",
      "            all_proba = []\n",
      "\n",
      "            for k in range(self.n_outputs_):\n",
      "                proba_k = proba[:, k, :self.n_classes_[k]]\n",
      "                normalizer = proba_k.sum(axis=1)[:, np.newaxis]\n",
      "                normalizer[normalizer == 0.0] = 1.0\n",
      "                proba_k /= normalizer\n",
      "                all_proba.append(proba_k)\n",
      "\n",
      "            return all_proba\n",
      "\n",
      "    def predict_log_proba(self, X):\n",
      "        \"\"\"Predict class log-probabilities of the input samples X.\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csr_matrix``.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        proba : ndarray of shape (n_samples, n_classes) or list of n_outputs \\\n",
      "            such arrays if n_outputs > 1\n",
      "            The class log-probabilities of the input samples. The order of the\n",
      "            classes corresponds to that in the attribute :term:`classes_`.\n",
      "        \"\"\"\n",
      "        proba = self.predict_proba(X)\n",
      "\n",
      "        if self.n_outputs_ == 1:\n",
      "            return np.log(proba)\n",
      "\n",
      "        else:\n",
      "            for k in range(self.n_outputs_):\n",
      "                proba[k] = np.log(proba[k])\n",
      "\n",
      "            return proba\n",
      "\n",
      "\n",
      "class DecisionTreeRegressor(RegressorMixin, BaseDecisionTree):\n",
      "    \"\"\"A decision tree regressor.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"mse\", \"friedman_mse\", \"mae\"}, default=\"mse\"\n",
      "        The function to measure the quality of a split. Supported criteria\n",
      "        are \"mse\" for the mean squared error, which is equal to variance\n",
      "        reduction as feature selection criterion and minimizes the L2 loss\n",
      "        using the mean of each terminal node, \"friedman_mse\", which uses mean\n",
      "        squared error with Friedman's improvement score for potential splits,\n",
      "        and \"mae\" for the mean absolute error, which minimizes the L1 loss\n",
      "        using the median of each terminal node.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "           Mean Absolute Error (MAE) criterion.\n",
      "\n",
      "    splitter : {\"best\", \"random\"}, default=\"best\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a fraction and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If \"auto\", then `max_features=n_features`.\n",
      "        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "        - If \"log2\", then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int or RandomState, default=None\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, (default=1e-7)\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "    presort : deprecated, default='deprecated'\n",
      "        This parameter is deprecated and will be removed in v0.24.\n",
      "\n",
      "        .. deprecated:: 0.22\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        The feature importances.\n",
      "        The higher, the more important the feature.\n",
      "        The importance of a feature is computed as the\n",
      "        (normalized) total reduction of the criterion brought\n",
      "        by that feature. It is also known as the Gini importance [4]_.\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    DecisionTreeClassifier : A decision tree classifier.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    The features are always randomly permuted at each split. Therefore,\n",
      "    the best found split may vary, even with the same training data and\n",
      "    ``max_features=n_features``, if the improvement of the criterion is\n",
      "    identical for several splits enumerated during the search of the best\n",
      "    split. To obtain a deterministic behaviour during fitting,\n",
      "    ``random_state`` has to be fixed.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      "\n",
      "    .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      "           and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      "\n",
      "    .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      "           Learning\", Springer, 2009.\n",
      "\n",
      "    .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      "           https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_boston\n",
      "    >>> from sklearn.model_selection import cross_val_score\n",
      "    >>> from sklearn.tree import DecisionTreeRegressor\n",
      "    >>> X, y = load_boston(return_X_y=True)\n",
      "    >>> regressor = DecisionTreeRegressor(random_state=0)\n",
      "    >>> cross_val_score(regressor, X, y, cv=10)\n",
      "    ...                    # doctest: +SKIP\n",
      "    ...\n",
      "    array([ 0.61..., 0.57..., -0.34..., 0.41..., 0.75...,\n",
      "            0.07..., 0.29..., 0.33..., -1.42..., -1.77...])\n",
      "    \"\"\"\n",
      "    def __init__(self,\n",
      "                 criterion=\"mse\",\n",
      "                 splitter=\"best\",\n",
      "                 max_depth=None,\n",
      "                 min_samples_split=2,\n",
      "                 min_samples_leaf=1,\n",
      "                 min_weight_fraction_leaf=0.,\n",
      "                 max_features=None,\n",
      "                 random_state=None,\n",
      "                 max_leaf_nodes=None,\n",
      "                 min_impurity_decrease=0.,\n",
      "                 min_impurity_split=None,\n",
      "                 presort='deprecated',\n",
      "                 ccp_alpha=0.0):\n",
      "        super().__init__(\n",
      "            criterion=criterion,\n",
      "            splitter=splitter,\n",
      "            max_depth=max_depth,\n",
      "            min_samples_split=min_samples_split,\n",
      "            min_samples_leaf=min_samples_leaf,\n",
      "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
      "            max_features=max_features,\n",
      "            max_leaf_nodes=max_leaf_nodes,\n",
      "            random_state=random_state,\n",
      "            min_impurity_decrease=min_impurity_decrease,\n",
      "            min_impurity_split=min_impurity_split,\n",
      "            presort=presort,\n",
      "            ccp_alpha=ccp_alpha)\n",
      "\n",
      "    def fit(self, X, y, sample_weight=None, check_input=True,\n",
      "            X_idx_sorted=None):\n",
      "        \"\"\"Build a decision tree regressor from the training set (X, y).\n",
      "\n",
      "        Parameters\n",
      "        ----------\n",
      "        X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      "            The training input samples. Internally, it will be converted to\n",
      "            ``dtype=np.float32`` and if a sparse matrix is provided\n",
      "            to a sparse ``csc_matrix``.\n",
      "\n",
      "        y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      "            The target values (real numbers). Use ``dtype=np.float64`` and\n",
      "            ``order='C'`` for maximum efficiency.\n",
      "\n",
      "        sample_weight : array-like of shape (n_samples,), default=None\n",
      "            Sample weights. If None, then samples are equally weighted. Splits\n",
      "            that would create child nodes with net zero or negative weight are\n",
      "            ignored while searching for a split in each node.\n",
      "\n",
      "        check_input : bool, default=True\n",
      "            Allow to bypass several input checking.\n",
      "            Don't use this parameter unless you know what you do.\n",
      "\n",
      "        X_idx_sorted : array-like of shape (n_samples, n_features), \\\n",
      "            default=None\n",
      "            The indexes of the sorted training input samples. If many tree\n",
      "            are grown on the same dataset, this allows the ordering to be\n",
      "            cached between trees. If None, the data will be sorted here.\n",
      "            Don't use this parameter unless you know what to do.\n",
      "\n",
      "        Returns\n",
      "        -------\n",
      "        self : DecisionTreeRegressor\n",
      "            Fitted estimator.\n",
      "        \"\"\"\n",
      "\n",
      "        super().fit(\n",
      "            X, y,\n",
      "            sample_weight=sample_weight,\n",
      "            check_input=check_input,\n",
      "            X_idx_sorted=X_idx_sorted)\n",
      "        return self\n",
      "\n",
      "    @property\n",
      "    def classes_(self):\n",
      "        # TODO: Remove method in 0.24\n",
      "        msg = (\"the classes_ attribute is to be deprecated from version \"\n",
      "               \"0.22 and will be removed in 0.24.\")\n",
      "        warnings.warn(msg, FutureWarning)\n",
      "        return np.array([None] * self.n_outputs_)\n",
      "\n",
      "    @property\n",
      "    def n_classes_(self):\n",
      "        # TODO: Remove method in 0.24\n",
      "        msg = (\"the n_classes_ attribute is to be deprecated from version \"\n",
      "               \"0.22 and will be removed in 0.24.\")\n",
      "        warnings.warn(msg, FutureWarning)\n",
      "        return np.array([1] * self.n_outputs_, dtype=np.intp)\n",
      "\n",
      "\n",
      "class ExtraTreeClassifier(DecisionTreeClassifier):\n",
      "    \"\"\"An extremely randomized tree classifier.\n",
      "\n",
      "    Extra-trees differ from classic decision trees in the way they are built.\n",
      "    When looking for the best split to separate the samples of a node into two\n",
      "    groups, random splits are drawn for each of the `max_features` randomly\n",
      "    selected features and the best split among those is chosen. When\n",
      "    `max_features` is set 1, this amounts to building a totally random\n",
      "    decision tree.\n",
      "\n",
      "    Warning: Extra-trees should only be used within ensemble methods.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      "        The function to measure the quality of a split. Supported criteria are\n",
      "        \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      "\n",
      "    splitter : {\"random\", \"best\"}, default=\"random\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float, {\"auto\", \"sqrt\", \"log2\"} or None, default=\"auto\"\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "            - If int, then consider `max_features` features at each split.\n",
      "            - If float, then `max_features` is a fraction and\n",
      "              `int(max_features * n_features)` features are considered at each\n",
      "              split.\n",
      "            - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "            - If \"log2\", then `max_features=log2(n_features)`.\n",
      "            - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int or RandomState, default=None\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, (default=1e-7)\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "    class_weight : dict, list of dict or \"balanced\", default=None\n",
      "        Weights associated with classes in the form ``{class_label: weight}``.\n",
      "        If None, all classes are supposed to have weight one. For\n",
      "        multi-output problems, a list of dicts can be provided in the same\n",
      "        order as the columns of y.\n",
      "\n",
      "        Note that for multioutput (including multilabel) weights should be\n",
      "        defined for each class of every column in its own dict. For example,\n",
      "        for four-class multilabel classification weights should be\n",
      "        [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      "        [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      "\n",
      "        The \"balanced\" mode uses the values of y to automatically adjust\n",
      "        weights inversely proportional to class frequencies in the input data\n",
      "        as ``n_samples / (n_classes * np.bincount(y))``\n",
      "\n",
      "        For multi-output, the weights of each column of y will be multiplied.\n",
      "\n",
      "        Note that these weights will be multiplied with sample_weight (passed\n",
      "        through the fit method) if sample_weight is specified.\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
      "        The classes labels (single output problem),\n",
      "        or a list of arrays of class labels (multi-output problem).\n",
      "\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_classes_ : int or list of int\n",
      "        The number of classes (for single output problems),\n",
      "        or a list containing the number of classes for each\n",
      "        output (for multi-output problems).\n",
      "\n",
      "    feature_importances_ : ndarray of shape (n_features,)\n",
      "        Return the feature importances (the higher, the more important the\n",
      "        feature).\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ExtraTreeRegressor : An extremely randomized tree regressor.\n",
      "    sklearn.ensemble.ExtraTreesClassifier : An extra-trees classifier.\n",
      "    sklearn.ensemble.ExtraTreesRegressor : An extra-trees regressor.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized trees\",\n",
      "           Machine Learning, 63(1), 3-42, 2006.\n",
      "    \"\"\"\n",
      "    def __init__(self,\n",
      "                 criterion=\"gini\",\n",
      "                 splitter=\"random\",\n",
      "                 max_depth=None,\n",
      "                 min_samples_split=2,\n",
      "                 min_samples_leaf=1,\n",
      "                 min_weight_fraction_leaf=0.,\n",
      "                 max_features=\"auto\",\n",
      "                 random_state=None,\n",
      "                 max_leaf_nodes=None,\n",
      "                 min_impurity_decrease=0.,\n",
      "                 min_impurity_split=None,\n",
      "                 class_weight=None,\n",
      "                 ccp_alpha=0.0):\n",
      "        super().__init__(\n",
      "            criterion=criterion,\n",
      "            splitter=splitter,\n",
      "            max_depth=max_depth,\n",
      "            min_samples_split=min_samples_split,\n",
      "            min_samples_leaf=min_samples_leaf,\n",
      "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
      "            max_features=max_features,\n",
      "            max_leaf_nodes=max_leaf_nodes,\n",
      "            class_weight=class_weight,\n",
      "            min_impurity_decrease=min_impurity_decrease,\n",
      "            min_impurity_split=min_impurity_split,\n",
      "            random_state=random_state,\n",
      "            ccp_alpha=ccp_alpha)\n",
      "\n",
      "\n",
      "class ExtraTreeRegressor(DecisionTreeRegressor):\n",
      "    \"\"\"An extremely randomized tree regressor.\n",
      "\n",
      "    Extra-trees differ from classic decision trees in the way they are built.\n",
      "    When looking for the best split to separate the samples of a node into two\n",
      "    groups, random splits are drawn for each of the `max_features` randomly\n",
      "    selected features and the best split among those is chosen. When\n",
      "    `max_features` is set 1, this amounts to building a totally random\n",
      "    decision tree.\n",
      "\n",
      "    Warning: Extra-trees should only be used within ensemble methods.\n",
      "\n",
      "    Read more in the :ref:`User Guide <tree>`.\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    criterion : {\"mse\", \"friedman_mse\", \"mae\"}, default=\"mse\"\n",
      "        The function to measure the quality of a split. Supported criteria\n",
      "        are \"mse\" for the mean squared error, which is equal to variance\n",
      "        reduction as feature selection criterion, and \"mae\" for the mean\n",
      "        absolute error.\n",
      "\n",
      "        .. versionadded:: 0.18\n",
      "           Mean Absolute Error (MAE) criterion.\n",
      "\n",
      "    splitter : {\"random\", \"best\"}, default=\"random\"\n",
      "        The strategy used to choose the split at each node. Supported\n",
      "        strategies are \"best\" to choose the best split and \"random\" to choose\n",
      "        the best random split.\n",
      "\n",
      "    max_depth : int, default=None\n",
      "        The maximum depth of the tree. If None, then nodes are expanded until\n",
      "        all leaves are pure or until all leaves contain less than\n",
      "        min_samples_split samples.\n",
      "\n",
      "    min_samples_split : int or float, default=2\n",
      "        The minimum number of samples required to split an internal node:\n",
      "\n",
      "        - If int, then consider `min_samples_split` as the minimum number.\n",
      "        - If float, then `min_samples_split` is a fraction and\n",
      "          `ceil(min_samples_split * n_samples)` are the minimum\n",
      "          number of samples for each split.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_samples_leaf : int or float, default=1\n",
      "        The minimum number of samples required to be at a leaf node.\n",
      "        A split point at any depth will only be considered if it leaves at\n",
      "        least ``min_samples_leaf`` training samples in each of the left and\n",
      "        right branches.  This may have the effect of smoothing the model,\n",
      "        especially in regression.\n",
      "\n",
      "        - If int, then consider `min_samples_leaf` as the minimum number.\n",
      "        - If float, then `min_samples_leaf` is a fraction and\n",
      "          `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      "          number of samples for each node.\n",
      "\n",
      "        .. versionchanged:: 0.18\n",
      "           Added float values for fractions.\n",
      "\n",
      "    min_weight_fraction_leaf : float, default=0.0\n",
      "        The minimum weighted fraction of the sum total of weights (of all\n",
      "        the input samples) required to be at a leaf node. Samples have\n",
      "        equal weight when sample_weight is not provided.\n",
      "\n",
      "    max_features : int, float, {\"auto\", \"sqrt\", \"log2\"} or None, default=\"auto\"\n",
      "        The number of features to consider when looking for the best split:\n",
      "\n",
      "        - If int, then consider `max_features` features at each split.\n",
      "        - If float, then `max_features` is a fraction and\n",
      "          `int(max_features * n_features)` features are considered at each\n",
      "          split.\n",
      "        - If \"auto\", then `max_features=n_features`.\n",
      "        - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      "        - If \"log2\", then `max_features=log2(n_features)`.\n",
      "        - If None, then `max_features=n_features`.\n",
      "\n",
      "        Note: the search for a split does not stop until at least one\n",
      "        valid partition of the node samples is found, even if it requires to\n",
      "        effectively inspect more than ``max_features`` features.\n",
      "\n",
      "    random_state : int or RandomState, default=None\n",
      "        If int, random_state is the seed used by the random number generator;\n",
      "        If RandomState instance, random_state is the random number generator;\n",
      "        If None, the random number generator is the RandomState instance used\n",
      "        by `np.random`.\n",
      "\n",
      "    min_impurity_decrease : float, default=0.0\n",
      "        A node will be split if this split induces a decrease of the impurity\n",
      "        greater than or equal to this value.\n",
      "\n",
      "        The weighted impurity decrease equation is the following::\n",
      "\n",
      "            N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      "                                - N_t_L / N_t * left_impurity)\n",
      "\n",
      "        where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      "        samples at the current node, ``N_t_L`` is the number of samples in the\n",
      "        left child, and ``N_t_R`` is the number of samples in the right child.\n",
      "\n",
      "        ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      "        if ``sample_weight`` is passed.\n",
      "\n",
      "        .. versionadded:: 0.19\n",
      "\n",
      "    min_impurity_split : float, (default=1e-7)\n",
      "        Threshold for early stopping in tree growth. A node will split\n",
      "        if its impurity is above the threshold, otherwise it is a leaf.\n",
      "\n",
      "        .. deprecated:: 0.19\n",
      "           ``min_impurity_split`` has been deprecated in favor of\n",
      "           ``min_impurity_decrease`` in 0.19. The default value of\n",
      "           ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      "           will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      "\n",
      "    max_leaf_nodes : int, default=None\n",
      "        Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      "        Best nodes are defined as relative reduction in impurity.\n",
      "        If None then unlimited number of leaf nodes.\n",
      "\n",
      "    ccp_alpha : non-negative float, default=0.0\n",
      "        Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      "        subtree with the largest cost complexity that is smaller than\n",
      "        ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      "        :ref:`minimal_cost_complexity_pruning` for details.\n",
      "\n",
      "        .. versionadded:: 0.22\n",
      "\n",
      "    Attributes\n",
      "    ----------\n",
      "    max_features_ : int\n",
      "        The inferred value of max_features.\n",
      "\n",
      "    n_features_ : int\n",
      "        The number of features when ``fit`` is performed.\n",
      "\n",
      "    n_outputs_ : int\n",
      "        The number of outputs when ``fit`` is performed.\n",
      "\n",
      "    tree_ : Tree\n",
      "        The underlying Tree object. Please refer to\n",
      "        ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      "        :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      "        for basic usage of these attributes.\n",
      "\n",
      "    See Also\n",
      "    --------\n",
      "    ExtraTreeClassifier : An extremely randomized tree classifier.\n",
      "    sklearn.ensemble.ExtraTreesClassifier : An extra-trees classifier.\n",
      "    sklearn.ensemble.ExtraTreesRegressor : An extra-trees regressor.\n",
      "\n",
      "    Notes\n",
      "    -----\n",
      "    The default values for the parameters controlling the size of the trees\n",
      "    (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      "    unpruned trees which can potentially be very large on some data sets. To\n",
      "    reduce memory consumption, the complexity and size of the trees should be\n",
      "    controlled by setting those parameter values.\n",
      "\n",
      "    References\n",
      "    ----------\n",
      "\n",
      "    .. [1] P. Geurts, D. Ernst., and L. Wehenkel, \"Extremely randomized trees\",\n",
      "           Machine Learning, 63(1), 3-42, 2006.\n",
      "\n",
      "    Examples\n",
      "    --------\n",
      "    >>> from sklearn.datasets import load_boston\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> from sklearn.ensemble import BaggingRegressor\n",
      "    >>> from sklearn.tree import ExtraTreeRegressor\n",
      "    >>> X, y = load_boston(return_X_y=True)\n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, random_state=0)\n",
      "    >>> extra_tree = ExtraTreeRegressor(random_state=0)\n",
      "    >>> reg = BaggingRegressor(extra_tree, random_state=0).fit(\n",
      "    ...     X_train, y_train)\n",
      "    >>> reg.score(X_test, y_test)\n",
      "    0.7823...\n",
      "    \"\"\"\n",
      "    def __init__(self,\n",
      "                 criterion=\"mse\",\n",
      "                 splitter=\"random\",\n",
      "                 max_depth=None,\n",
      "                 min_samples_split=2,\n",
      "                 min_samples_leaf=1,\n",
      "                 min_weight_fraction_leaf=0.,\n",
      "                 max_features=\"auto\",\n",
      "                 random_state=None,\n",
      "                 min_impurity_decrease=0.,\n",
      "                 min_impurity_split=None,\n",
      "                 max_leaf_nodes=None,\n",
      "                 ccp_alpha=0.0):\n",
      "        super().__init__(\n",
      "            criterion=criterion,\n",
      "            splitter=splitter,\n",
      "            max_depth=max_depth,\n",
      "            min_samples_split=min_samples_split,\n",
      "            min_samples_leaf=min_samples_leaf,\n",
      "            min_weight_fraction_leaf=min_weight_fraction_leaf,\n",
      "            max_features=max_features,\n",
      "            max_leaf_nodes=max_leaf_nodes,\n",
      "            min_impurity_decrease=min_impurity_decrease,\n",
      "            min_impurity_split=min_impurity_split,\n",
      "            random_state=random_state,\n",
      "            ccp_alpha=ccp_alpha)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(open(inspect.getsourcefile(BaseDecisionTree)).read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import BaseDecisionTree's imports.\n",
    "\n",
    "If we could simply `exec()` this file, we could theoretically import all of `BaseDecisionTree`'s dependencies. Unfortunately, we cannot do that straightforwardly. The relative imports, however, are problematic. The following code replaces the relative imports then executes the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree._classes as tree\n",
    "exec(inspect.getsource(tree).replace('from ..', 'from sklearn.')\\\n",
    "     .replace('from ._', 'from sklearn.tree._')\\\n",
    "     .replace('from . ', 'from sklearn.tree '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try the patch again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATCH: n_samples=150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=0, splitter='best')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(iris.data, iris.target)  # Call the method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see it works and we have a means to tease this function apart more, which we leave as an exercise for the reader. ;-)\n",
    "\n",
    "# Conclusion\n",
    "\n",
    "This concludes this workbook, happy hacking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
